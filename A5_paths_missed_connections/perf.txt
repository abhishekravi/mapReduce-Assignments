# Configuration parameters 

# Number of Iterations per Configuration
num = 3

# Test Results File
results = results.csv

jar = job.jar

# Local Hadoop Home
hadoop.home = /usr/local/hadoop

# AWS S3 Initialization
region = us-west-2
check.bucket = s3://
check.input = s3:///input
check.logs = s3:///logs
delete.output = s3:///output
upload.jar = s3://

# AWS EMR Cluster Configuration
cluster.name = MyCluster1
step.name = Step
release.label = emr-4.2.0
log.uri = s3://pdmrbucket/logs
service.role = EMR_DefaultRole
job.flow.role = EMR_EC2_DefaultRole
ec2.key.name = 
instance.count = 5
keep.job.flow.alive = false
master.instance.type = m3.xlarge
slave.instance.type = m3.xlarge


# name of the job (optional)
name = myjob
# main class (required)
main = A5
# input directory  (required)
input = /home/raiden/all
# output directory (optional)
output =
# list of argument strings (optional)
arguments =""
